<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>BRIEFB2.html</title>
  <meta name="generator" content="Haroopad 0.13.1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>div.oembedall-githubrepos{border:1px solid #DDD;border-radius:4px;list-style-type:none;margin:0 0 10px;padding:8px 10px 0;font:13.34px/1.4 helvetica,arial,freesans,clean,sans-serif;width:452px;background-color:#fff}div.oembedall-githubrepos .oembedall-body{background:-moz-linear-gradient(center top,#FAFAFA,#EFEFEF);background:-webkit-gradient(linear,left top,left bottom,from(#FAFAFA),to(#EFEFEF));border-bottom-left-radius:4px;border-bottom-right-radius:4px;border-top:1px solid #EEE;margin-left:-10px;margin-top:8px;padding:5px 10px;width:100%}div.oembedall-githubrepos h3{font-size:14px;margin:0;padding-left:18px;white-space:nowrap}div.oembedall-githubrepos p.oembedall-description{color:#444;font-size:12px;margin:0 0 3px}div.oembedall-githubrepos p.oembedall-updated-at{color:#888;font-size:11px;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats{border:none;float:right;font-size:11px;font-weight:700;padding-left:15px;position:relative;z-index:5;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats li{border:none;color:#666;display:inline-block;list-style-type:none;margin:0!important}div.oembedall-githubrepos ul.oembedall-repo-stats li a{background-color:transparent;border:none;color:#666!important;background-position:5px -2px;background-repeat:no-repeat;border-left:1px solid #DDD;display:inline-block;height:21px;line-height:21px;padding:0 5px 0 23px}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a{border-left:medium none;margin-right:-3px}div.oembedall-githubrepos ul.oembedall-repo-stats li a:hover{background:5px -27px no-repeat #4183C4;color:#FFF!important;text-decoration:none}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a:hover{border-bottom-left-radius:3px;border-top-left-radius:3px}ul.oembedall-repo-stats li:last-child a:hover{border-bottom-right-radius:3px;border-top-right-radius:3px}span.oembedall-closehide{background-color:#aaa;border-radius:2px;cursor:pointer;margin-right:3px}div.oembedall-container{margin-top:5px;text-align:left}.oembedall-ljuser{font-weight:700}.oembedall-ljuser img{vertical-align:bottom;border:0;padding-right:1px}.oembedall-stoqembed{border-bottom:1px dotted #999;float:left;overflow:hidden;width:730px;line-height:1;background:#FFF;color:#000;font-family:Arial,Liberation Sans,DejaVu Sans,sans-serif;font-size:80%;text-align:left;margin:0;padding:0}.oembedall-stoqembed a{color:#07C;text-decoration:none;margin:0;padding:0}.oembedall-stoqembed a:hover{text-decoration:underline}.oembedall-stoqembed a:visited{color:#4A6B82}.oembedall-stoqembed h3{font-family:Trebuchet MS,Liberation Sans,DejaVu Sans,sans-serif;font-size:130%;font-weight:700;margin:0;padding:0}.oembedall-stoqembed .oembedall-reputation-score{color:#444;font-size:120%;font-weight:700;margin-right:2px}.oembedall-stoqembed .oembedall-user-info{height:35px;width:185px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-gravatar32{float:left;height:32px;width:32px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-details{float:left;margin-left:5px;overflow:hidden;white-space:nowrap;width:145px}.oembedall-stoqembed .oembedall-question-hyperlink{font-weight:700}.oembedall-stoqembed .oembedall-stats{background:#EEE;margin:0 0 0 7px;padding:4px 7px 6px;width:58px}.oembedall-stoqembed .oembedall-statscontainer{float:left;margin-right:8px;width:86px}.oembedall-stoqembed .oembedall-votes{color:#555;padding:0 0 7px;text-align:center}.oembedall-stoqembed .oembedall-vote-count-post{font-size:240%;color:#808185;display:block;font-weight:700}.oembedall-stoqembed .oembedall-views{color:#999;padding-top:4px;text-align:center}.oembedall-stoqembed .oembedall-status{margin-top:-3px;padding:4px 0;text-align:center;background:#75845C;color:#FFF}.oembedall-stoqembed .oembedall-status strong{color:#FFF;display:block;font-size:140%}.oembedall-stoqembed .oembedall-summary{float:left;width:635px}.oembedall-stoqembed .oembedall-excerpt{line-height:1.2;margin:0;padding:0 0 5px}.oembedall-stoqembed .oembedall-tags{float:left;line-height:18px}.oembedall-stoqembed .oembedall-tags a:hover{text-decoration:none}.oembedall-stoqembed .oembedall-post-tag{background-color:#E0EAF1;border-bottom:1px solid #3E6D8E;border-right:1px solid #7F9FB6;color:#3E6D8E;font-size:90%;line-height:2.4;margin:2px 2px 2px 0;padding:3px 4px;text-decoration:none;white-space:nowrap}.oembedall-stoqembed .oembedall-post-tag:hover{background-color:#3E6D8E;border-bottom:1px solid #37607D;border-right:1px solid #37607D;color:#E0EAF1}.oembedall-stoqembed .oembedall-fr{float:right}.oembedall-stoqembed .oembedall-statsarrow{background-image:url(http://cdn.sstatic.net/stackoverflow/img/sprites.png?v=3);background-repeat:no-repeat;overflow:hidden;background-position:0 -435px;float:right;height:13px;margin-top:12px;width:7px}.oembedall-facebook1{border:1px solid #1A3C6C;padding:0;font:13.34px/1.4 verdana;width:500px}.oembedall-facebook2{background-color:#627add}.oembedall-facebook2 a{color:#e8e8e8;text-decoration:none}.oembedall-facebookBody{background-color:#fff;vertical-align:top;padding:5px}.oembedall-facebookBody .contents{display:inline-block;width:100%}.oembedall-facebookBody div img{float:left;margin-right:5px}div.oembedall-lanyard{-webkit-box-shadow:none;-webkit-transition-delay:0s;-webkit-transition-duration:.4000000059604645s;-webkit-transition-property:width;-webkit-transition-timing-function:cubic-bezier(0.42,0,.58,1);background-attachment:scroll;background-clip:border-box;background-color:transparent;background-image:none;background-origin:padding-box;border-width:0;box-shadow:none;color:#112644;display:block;float:left;font-family:'Trebuchet MS',Trebuchet,sans-serif;font-size:16px;height:253px;line-height:19px;margin:0;max-width:none;min-height:0;outline:#112644 0;overflow-x:visible;overflow-y:visible;padding:0;position:relative;text-align:left;vertical-align:baseline;width:804px}div.oembedall-lanyard .tagline{font-size:1.5em}div.oembedall-lanyard .wrapper{overflow:hidden;clear:both}div.oembedall-lanyard .split{float:left;display:inline}div.oembedall-lanyard .prominent-place .flag:active,div.oembedall-lanyard .prominent-place .flag:focus,div.oembedall-lanyard .prominent-place .flag:hover,div.oembedall-lanyard .prominent-place .flag:link,div.oembedall-lanyard .prominent-place .flag:visited{float:left;display:block;width:48px;height:48px;position:relative;top:-5px;margin-right:10px}div.oembedall-lanyard .place-context{font-size:.889em}div.oembedall-lanyard .prominent-place .sub-place{display:block}div.oembedall-lanyard .prominent-place{font-size:1.125em;line-height:1.1em;font-weight:400}div.oembedall-lanyard .main-date{color:#8CB4E0;font-weight:700;line-height:1.1}div.oembedall-lanyard .first{width:48.57%;margin:0 0 0 2.857%}.mermaid .label{color:#333}.node circle,.node polygon,.node rect{fill:#cde498;stroke:#13540c;stroke-width:1px}.edgePath .path{stroke:green;stroke-width:1.5px}.cluster rect{fill:#cdffb2;rx:40;stroke:#6eaa49;stroke-width:1px}.cluster text{fill:#333}.actor{stroke:#13540c;fill:#cde498}text.actor{fill:#000;stroke:none}.actor-line{stroke:grey}.messageLine0{stroke-width:1.5;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#333}.messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#arrowhead{fill:#333}#crosshead path{fill:#333!important;stroke:#333!important}.messageText{fill:#333;stroke:none}.labelBox{stroke:#326932;fill:#cde498}.labelText,.loopText{fill:#000;stroke:none}.loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#326932}.note{stroke:#6eaa49;fill:#fff5ad}.noteText{fill:#000;stroke:none;font-family:'trebuchet ms',verdana,arial;font-size:14px}.section{stroke:none;opacity:.2}.section0,.section2{fill:#6eaa49}.section1,.section3{fill:#fff;opacity:.2}.sectionTitle0,.sectionTitle1,.sectionTitle2,.sectionTitle3{fill:#333}.sectionTitle{text-anchor:start;font-size:11px;text-height:14px}.grid .tick{stroke:lightgrey;opacity:.3;shape-rendering:crispEdges}.grid path{stroke-width:0}.today{fill:none;stroke:red;stroke-width:2px}.task{stroke-width:2}.taskText{text-anchor:middle;font-size:11px}.taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}.taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}.taskText0,.taskText1,.taskText2,.taskText3{fill:#fff}.task0,.task1,.task2,.task3{fill:#487e3a;stroke:#13540c}.taskTextOutside0,.taskTextOutside1,.taskTextOutside2,.taskTextOutside3{fill:#000}.active0,.active1,.active2,.active3{fill:#cde498;stroke:#13540c}.activeText0,.activeText1,.activeText2,.activeText3{fill:#000!important}.done0,.done1,.done2,.done3{stroke:grey;fill:lightgrey;stroke-width:2}.doneText0,.doneText1,.doneText2,.doneText3{fill:#000!important}.crit0,.crit1,.crit2,.crit3{stroke:#f88;fill:red;stroke-width:2}.activeCrit0,.activeCrit1,.activeCrit2,.activeCrit3{stroke:#f88;fill:#cde498;stroke-width:2}.doneCrit0,.doneCrit1,.doneCrit2,.doneCrit3{stroke:#f88;fill:lightgrey;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}.activeCritText0,.activeCritText1,.activeCritText2,.activeCritText3,.doneCritText0,.doneCritText1,.doneCritText2,.doneCritText3{fill:#000!important}.titleText{text-anchor:middle;font-size:18px;fill:#000}text{font-family:'trebuchet ms',verdana,arial;font-size:14px}html{height:100%}body{margin:0!important;padding:5px 20px 26px!important;background-color:#fff;font-family:"Lucida Grande","Segoe UI","Apple SD Gothic Neo","Malgun Gothic","Lucida Sans Unicode",Helvetica,Arial,sans-serif;font-size:.9em;overflow-x:hidden;overflow-y:auto}br,h1,h2,h3,h4,h5,h6{clear:both}hr.page{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x;border:0;height:3px;padding:0}hr.underscore{border-top-style:dashed!important}body >:first-child{margin-top:0!important}img.plugin{box-shadow:0 1px 3px rgba(0,0,0,.1);border-radius:3px}iframe{border:0}figure{-webkit-margin-before:0;-webkit-margin-after:0;-webkit-margin-start:0;-webkit-margin-end:0}kbd{border:1px solid #aaa;-moz-border-radius:2px;-webkit-border-radius:2px;border-radius:2px;-moz-box-shadow:1px 2px 2px #ddd;-webkit-box-shadow:1px 2px 2px #ddd;box-shadow:1px 2px 2px #ddd;background-color:#f9f9f9;background-image:-moz-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-o-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-webkit-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:linear-gradient(top,#eee,#f9f9f9,#eee);padding:1px 3px;font-family:inherit;font-size:.85em}.oembeded .oembed_photo{display:inline-block}img[data-echo]{margin:25px 0;width:100px;height:100px;background:url(../img/ajax.gif) center center no-repeat #fff}.spinner{display:inline-block;width:10px;height:10px;margin-bottom:-.1em;border:2px solid rgba(0,0,0,.5);border-top-color:transparent;border-radius:100%;-webkit-animation:spin 1s infinite linear;animation:spin 1s infinite linear}.spinner:after{content:'';display:block;width:0;height:0;position:absolute;top:-6px;left:0;border:4px solid transparent;border-bottom-color:rgba(0,0,0,.5);-webkit-transform:rotate(45deg);transform:rotate(45deg)}@-webkit-keyframes spin{to{-webkit-transform:rotate(360deg)}}@keyframes spin{to{transform:rotate(360deg)}}p.toc{margin:0!important}p.toc ul{padding-left:10px}p.toc>ul{padding:10px;margin:0 10px;display:inline-block;border:1px solid #ededed;border-radius:5px}p.toc li,p.toc ul{list-style-type:none}p.toc li{width:100%;padding:0;overflow:hidden}p.toc li a::after{content:"."}p.toc li a:before{content:"• "}p.toc h5{text-transform:uppercase}p.toc .title{float:left;padding-right:3px}p.toc .number{margin:0;float:right;padding-left:3px;background:#fff;display:none}input.task-list-item{margin-left:-1.62em}.markdown{font-family:"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;padding:20px}.markdown a{text-decoration:none;vertical-align:baseline}.markdown a:hover{text-decoration:underline}.markdown h1{font-size:2.2em;font-weight:700;margin:1.5em 0 1em}.markdown h2{font-size:1.8em;font-weight:700;margin:1.275em 0 .85em}.markdown h3{font-size:1.6em;font-weight:700;margin:1.125em 0 .75em}.markdown h4{font-size:1.4em;font-weight:700;margin:.99em 0 .66em}.markdown h5{font-size:1.2em;font-weight:700;margin:.855em 0 .57em}.markdown h6{font-size:1em;font-weight:700;margin:.75em 0 .5em}.markdown h1+p,.markdown h1:first-child,.markdown h2+p,.markdown h2:first-child,.markdown h3+p,.markdown h3:first-child,.markdown h4+p,.markdown h4:first-child,.markdown h5+p,.markdown h5:first-child,.markdown h6+p,.markdown h6:first-child{margin-top:0}.markdown hr{border:1px solid #ccc}.markdown p{margin:1em 0;word-wrap:break-word}.markdown ol{list-style-type:decimal}.markdown li{display:list-item;line-height:1.4em}.markdown blockquote{margin:1em 20px}.markdown blockquote>:first-child{margin-top:0}.markdown blockquote>:last-child{margin-bottom:0}.markdown blockquote cite:before{content:'\2014 \00A0'}.markdown .code{border-radius:3px;word-wrap:break-word}.markdown pre{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;overflow:auto;padding:.5em}.markdown pre code{border:0;display:block}.markdown pre>code{font-family:Consolas,Inconsolata,Courier,monospace;font-weight:700;white-space:pre;margin:0}.markdown code{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;padding:0 5px;margin:0 2px}.markdown img{max-width:100%}.markdown mark{color:#000;background-color:#fcf8e3}.markdown table{padding:0;border-collapse:collapse;border-spacing:0;margin-bottom:16px}.markdown table tr td,.markdown table tr th{border:1px solid #ccc;margin:0;padding:6px 13px}.markdown table tr th{font-weight:700}.markdown table tr th>:first-child{margin-top:0}.markdown table tr th>:last-child{margin-bottom:0}.markdown table tr td>:first-child{margin-top:0}.markdown table tr td>:last-child{margin-bottom:0}@import url(http://fonts.googleapis.com/css?family=Roboto+Condensed:300italic,400italic,700italic,400,300,700);.haroopad{padding:20px;color:#222;font-size:15px;font-family:"Roboto Condensed",Tauri,"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;background:#fff;line-height:1.6;-webkit-font-smoothing:antialiased}.haroopad a{color:#3269a0}.haroopad a:hover{color:#4183c4}.haroopad h2{border-bottom:1px solid #e6e6e6}.haroopad h6{color:#777}.haroopad hr{border:1px solid #e6e6e6}.haroopad blockquote>code,.haroopad h1>code,.haroopad h2>code,.haroopad h3>code,.haroopad h4>code,.haroopad h5>code,.haroopad h6>code,.haroopad li>code,.haroopad p>code,.haroopad td>code{font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;font-size:85%;background-color:rgba(0,0,0,.02);padding:.2em .5em;border:1px solid #efefef}.haroopad pre>code{font-size:1em;letter-spacing:-1px;font-weight:700}.haroopad blockquote{border-left:4px solid #e6e6e6;padding:0 15px;color:#777}.haroopad table{background-color:#fafafa}.haroopad table tr td,.haroopad table tr th{border:1px solid #e6e6e6}.haroopad table tr:nth-child(2n){background-color:#f2f2f2}.hljs{display:block;overflow-x:auto;padding:.5em;background:#f0f0f0;-webkit-text-size-adjust:none}.hljs,.hljs-subst,.hljs-tag .hljs-title,.nginx .hljs-title{color:#000}.apache .hljs-cbracket,.apache .hljs-tag,.asciidoc .hljs-header,.bash .hljs-variable,.coffeescript .hljs-attribute,.django .hljs-variable,.erlang_repl .hljs-function_or_atom,.haml .hljs-symbol,.hljs-addition,.hljs-constant,.hljs-flow,.hljs-parent,.hljs-pragma,.hljs-preprocessor,.hljs-rules .hljs-value,.hljs-stream,.hljs-string,.hljs-tag .hljs-value,.hljs-template_tag,.hljs-title,.markdown .hljs-header,.ruby .hljs-symbol,.ruby .hljs-symbol .hljs-string,.smalltalk .hljs-class,.tex .hljs-command,.tex .hljs-special{color:#800}.asciidoc .hljs-blockquote,.diff .hljs-header,.hljs-annotation,.hljs-chunk,.hljs-comment,.markdown .hljs-blockquote,.smartquote{color:#888}.asciidoc .hljs-bullet,.asciidoc .hljs-link_url,.go .hljs-constant,.hljs-change,.hljs-date,.hljs-hexcolor,.hljs-literal,.hljs-number,.hljs-regexp,.lasso .hljs-variable,.makefile .hljs-variable,.markdown .hljs-bullet,.markdown .hljs-link_url,.smalltalk .hljs-char,.smalltalk .hljs-symbol{color:#080}.apache .hljs-sqbracket,.asciidoc .hljs-attribute,.asciidoc .hljs-link_label,.clojure .hljs-attribute,.coffeescript .hljs-property,.erlang_repl .hljs-reserved,.haml .hljs-bullet,.hljs-array,.hljs-attr_selector,.hljs-decorator,.hljs-deletion,.hljs-doctype,.hljs-envvar,.hljs-filter .hljs-argument,.hljs-important,.hljs-javadoc,.hljs-label,.hljs-localvars,.hljs-phony,.hljs-pi,.hljs-prompt,.hljs-pseudo,.hljs-shebang,.lasso .hljs-attribute,.markdown .hljs-link_label,.nginx .hljs-built_in,.ruby .hljs-string,.tex .hljs-formula,.vhdl .hljs-attribute{color:#88f}.apache .hljs-tag,.asciidoc .hljs-strong,.bash .hljs-variable,.css .hljs-tag,.hljs-built_in,.hljs-dartdoc,.hljs-id,.hljs-javadoctag,.hljs-keyword,.hljs-phpdoc,.hljs-request,.hljs-status,.hljs-title,.hljs-type,.hljs-typename,.hljs-winutils,.hljs-yardoctag,.markdown .hljs-strong,.smalltalk .hljs-class,.tex .hljs-command{font-weight:700}.asciidoc .hljs-emphasis,.markdown .hljs-emphasis{font-style:italic}.nginx .hljs-built_in{font-weight:400}.coffeescript .javascript,.javascript .xml,.lasso .markup,.tex .hljs-formula,.xml .css,.xml .hljs-cdata,.xml .javascript,.xml .vbscript{opacity:.5}.MathJax_Hover_Frame{border-radius:.25em;-webkit-border-radius:.25em;-moz-border-radius:.25em;-khtml-border-radius:.25em;box-shadow:0 0 15px #83A;-webkit-box-shadow:0 0 15px #83A;-moz-box-shadow:0 0 15px #83A;-khtml-box-shadow:0 0 15px #83A;border:1px solid #A6D!important;display:inline-block;position:absolute}.MathJax_Hover_Arrow{position:absolute;width:15px;height:11px;cursor:pointer}#MathJax_About{position:fixed;left:50%;width:auto;text-align:center;border:3px outset;padding:1em 2em;background-color:#DDD;color:#000;cursor:default;font-family:message-box;font-size:120%;font-style:normal;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;border-radius:15px;-webkit-border-radius:15px;-moz-border-radius:15px;-khtml-border-radius:15px;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_Menu{position:absolute;background-color:#fff;color:#000;width:auto;padding:2px;border:1px solid #CCC;margin:0;cursor:default;font:menu;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_MenuItem{padding:2px 2em;background:0 0}.MathJax_MenuArrow{position:absolute;right:.5em;color:#666}.MathJax_MenuActive .MathJax_MenuArrow{color:#fff}.MathJax_MenuArrow.RTL{left:.5em;right:auto}.MathJax_MenuCheck{position:absolute;left:.7em}.MathJax_MenuCheck.RTL{right:.7em;left:auto}.MathJax_MenuRadioCheck{position:absolute;left:1em}.MathJax_MenuRadioCheck.RTL{right:1em;left:auto}.MathJax_MenuLabel{padding:2px 2em 4px 1.33em;font-style:italic}.MathJax_MenuRule{border-top:1px solid #CCC;margin:4px 1px 0}.MathJax_MenuDisabled{color:GrayText}.MathJax_MenuActive{background-color:Highlight;color:HighlightText}.MathJax_Menu_Close{position:absolute;width:31px;height:31px;top:-15px;left:-15px}#MathJax_Zoom{position:absolute;background-color:#F0F0F0;overflow:auto;display:block;z-index:301;padding:.5em;border:1px solid #000;margin:0;font-weight:400;font-style:normal;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;box-shadow:5px 5px 15px #AAA;-webkit-box-shadow:5px 5px 15px #AAA;-moz-box-shadow:5px 5px 15px #AAA;-khtml-box-shadow:5px 5px 15px #AAA;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}#MathJax_ZoomOverlay{position:absolute;left:0;top:0;z-index:300;display:inline-block;width:100%;height:100%;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}#MathJax_ZoomFrame{position:relative;display:inline-block;height:0;width:0}#MathJax_ZoomEventTrap{position:absolute;left:0;top:0;z-index:302;display:inline-block;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1px;bottom:2px;background-color:#E6E6E6;border:1px solid #959595;margin:0;padding:2px 8px;z-index:102;color:#000;font-size:80%;width:auto;white-space:nowrap}#MathJax_MSIE_Frame{position:absolute;top:0;left:0;width:0;z-index:101;border:0;margin:0;padding:0}.MathJax_Error{color:#C00;font-style:italic}footer{position:fixed;font-size:.8em;text-align:right;bottom:0;margin-left:-25px;height:20px;width:100%}</style>
</head>
<body class="markdown haroopad">
<h4 id="introduction-to-graph-representations-and-graph-algorithms-for-biomedical-relation-extraction"><a name="introduction-to-graph-representations-and-graph-algorithms-for-biomedical-relation-extraction" href="#introduction-to-graph-representations-and-graph-algorithms-for-biomedical-relation-extraction"></a>Introduction to graph representations and graph algorithms for biomedical relation extraction</h4><blockquote>
<p>그래프는 어떻게 구성되어있고 어떤 알고리즘의 종류로 이용되는가.</p>
</blockquote><p>Narrative sentences 을 위한 Graph representation은<br>자연적으로 nodes and edges로 표현되는 the choice of information 으로 구성된다.</p><p>Common node choices 는<br>tokens<br>named entities<br>senmantically labeled named entity<br>and relations themselves within nested relations.<br>를 포함한다.</p><p>Those choices are<br>in the order of encoding increasingly enriched and complex semantic information.</p><blockquote>
<p>node들은 증가적으로 풍부하고 복잡한 의미론적 정보를 담고있는 순서다.</p>
</blockquote><p>Common edge choices 는<br>syntactic dependency,<br>syntactic constituency link,<br>event argument,<br>association<br>같은것을 edge로 본다.</p><p>These choices는<br>semantic and syntactic information을 the graph representation 에 통합시킨다.<br>to different degrees.</p><blockquote>
<p>그니까 위에꺼는 보통 graph representations을 진행할때<br>주로 Node 로 지정하는 것<br>주로 Edge 로 지정하는 것을 보여준다.</p>
</blockquote><p>Graph mining algorithms은 직접적으로 relations를 추출하기 위해 적용될 수 있고,<br>useful featrues를 구성하기 위해 적용될 수 있다.</p><p>빈번하게 사용되는 알고리즘은 다음에 따라 분류 할 수 있다.</p><ul>
<li>Some identify shortest path (or its variant) between concept pair ( 다익스트라 같은 기본적인 알고리즘을 사용해서 수행될 수 있는 알고리즘)</li><li>Some create association graphs then try to apply customized labels to them.</li><li>Some use subgraph matching to compare the similarity between subgraphs based on a score that aggregates node distances and edge distances</li><li>Some carry out frequent subgraph or subtree pattern mining to directly extract candidate relations</li><li>Some directrly parse graph representation of relations from sentences by intergrating the graph structure into the learning objective of the parsers.</li></ul><p>다음 섹션에서 state-of-the-art methods를 review할때,</p><p>우리는<br>그래프로 표현된 정보<br>graph 알고리즘<br>의도된 사용<br>을 중심으로 위 사항들을 Table 1에 요약해놓은 것 처럼</p><p>각 Method를 특징화 했다.</p><hr><h4 id="state-of-the-art-methods-for-biomedical-relation-extraction"><a name="state-of-the-art-methods-for-biomedical-relation-extraction" href="#state-of-the-art-methods-for-biomedical-relation-extraction"></a>State-of-the-art methods for biomedical relation extraction</h4><p>Biomedical relation extraction을 위한 방법론은 높은 관심을 받아왔다.<br>Conventional approaches는 co-occurrence statistics를 관련성을 위해 사용 한 것에 초점을 두고있다.</p><blockquote>
<p>과거의 방법들은 co-occurrence statistics로 relation로 찼아왔어</p>
</blockquote><p>몇몇 Clinical NLP systems는 직접만든 syntactic and semantic rules를 미리 서술된 semantic relations를 추출하는데 사용했다.<br>such as MedLEE and SemRep</p><p>그러나 이 clinical NLP systems는 새로운 subdomains에 적용시키기가 어렵다.</p><blockquote>
<p>서브도메인 다른 분야에서 사용하기가 어렵다 뭐 이런거같은데<br>응용하기가 어렵다?</p>
</blockquote><p>최근 연구는<br>‘relation을 추출하기 위해 자연어의 constituency and dependency structures를 충분히 탐색하고 일반화 할 수 있는 메소드를 개발하기 위해’<br>syntactic parsing에 더욱 더 초점을 두고 있다.</p><blockquote>
<p>여러 ‘subdomain,분야’ 에서 사용할 수 있고 성능이 보장된 메소드를 만들고자 하였나보넹</p>
</blockquote><p>In this section, we review the state-of-the-art approaches where graph (including tree) mining techniques are used to derive relations from syntactic or semantic parses.</p><p>In this section, 우리는 tree를 포함한 graph mining techniques에 대해서 review 할 것이다.<br>이 graph mining techniques은 syntactic or semantic parses으로부터 relations를 얻어오는데 사용되어 온것이다.</p><p>우리는 메소드들을 카테고리화 했다.<br>그것들의 문서가 주로 scientific publications or clinical narratives와 연관이 있는지 없는지에 따라.<br>왜냐하면 그 content difference가 the methods와 resources used to extract relations 에 영향을 종종 미치기 때문에.</p><blockquote>
<p>문서는 위에 parses를 가르키는 거 같고<br>scientific publications 나 clinical narratives와 연관이 있는지 없는지 ( content difference ) 에 따라 relation extraction을 위해 사용되는 the methods와 resource에 영향이 있다네<br>????????</p>
</blockquote><p>반면에,<br>community challenges는 계속해서 the development of state-of-the-art methods를 도와준다.</p><p>따라서,<br>각 카테고리에서,<br>우리는 they participate한 the challenge 를 가지고 있는 research work와 non-challege-participating한 research work로 묶었다.</p><p>그리고 우리는 algorithms들과 systems를 Table 1에 요약했다.</p><blockquote>
<p>????????</p>
</blockquote><hr class="underscore"><h5 id="relation-extraction-from-the-scientific-literature"><a name="relation-extraction-from-the-scientific-literature" href="#relation-extraction-from-the-scientific-literature"></a>Relation extraction from the scientific literature</h5><p>오래전부터 계속적으로 biomedical leterature text로부터 semantic relations를 추출하고자 하려는 노력은 종종 NLP techniques에 접근하고 발전시키려는 shared-task community challenges의 형태에서 이루어졌다.</p><p>주목할만한 community challenges들은<br>BioNLP shared tasks on mining,<br>BioCreative shared tasks on PPI extraction<br>DDIExtraction challenges on DDI extraction<br>을 포함하고 있다.</p><p>우리는 these shared tasks에서 the semantic relations를 특징화 시키기 위한 graph-based techniques를 사용하는 팀들의 많아지는것을 확인할 수 있었다.</p><p>These techniques는 자주 성능이 가장좋은 축에 있었다.</p><p>This section에서는 these challenges를 위해 개발된 the graph-based methodologies 를 볼 것이다.</p><p>우리는 오직 the shared task proceedings 가 full publications로써 승인된 the papers만 고려할 것이고,<br>the top-performing systems에만 집중할 것이다.</p><p>우리는 the f-measures of the best systems in each shared task 를 a representative evaluation으로써,<br>그리고 독자들에게 the callenge overviews for detailed and comprehensive evaluations.</p><blockquote>
<p>??????</p>
</blockquote><p>아마 these challenges로부터 수업을 받는 것을 통해, 실제 세계의 적용 (the field of pharmacogenomics) 또한 graph-based textmining methods의 개발과정에서 중요한 모멘텀을 볼것이다.</p><blockquote>
<p>아마 methods 제작과정에서 좋은 driver가 될 것이다 라는것 같음</p>
</blockquote><p>우리는 약리유전학에서의 발전을 위한 this section의 마지막 부분에 헌신했으며,<br>biomedical relation extraction에서<br>methodology-oriented research 에서 application-oriented research 로의<br>graph-based algorithms의 변화와 적응을 보여준다.</p><blockquote>
<p>그니까 방법론적 연구를 위한 algorithms에서 응용연구를 위한 algorithms으로 변경했구나.</p>
</blockquote><h6 id="bionlp-event-extraction-shared-tasks"><a name="bionlp-event-extraction-shared-tasks" href="#bionlp-event-extraction-shared-tasks"></a>BioNLP event extraction shared tasks</h6><p>Three BioNLP shared tasks (ST)는 the literature로부터의 biological events(relations)에 초점을 맞춰왔다<br>These tasks 는 the protein mentions를 input으로써 제공하고,<br>the participating teams 에게 미리정해진 set of semantic relations를 식별하라고 요구한다.<br>Teams 는 the protein mentios를 발견할 필요는 없다.</p><p>Three tasks로 구성된 BioNLP-ST-2009<br>core event detection<br>event argument recognition<br>negation/speculation detection<br>(all based on the GENIA corpus)</p><p>BioNLP-ST-2011 expanded the tasks and resources to cover more text types, event types and subject domains</p><p>BioNLP-ST-2011 added the following tasks:<br>Besides the continued GENIA task (GE),<br>epigenetics and post-translational modification (EPI),<br>infectious diseases (ID),<br>bacteria biotope (BB),<br>bacteria interaction (BI).</p><p>BioNLP-ST-2013 further expanded the application domains with<br>tasks of GE, BB,<br>cancer genetics (CG),<br>pathway curation (PC),<br>gene regulation ontology (GRO) [110]. </p><p>Table 2 describes those tasks in more detail.</p><hr class="underscore"><p>The typical event extraction workflow 는 Two general steps으로 나누어 질 수 있다.<br>Trigger detection<br>Argument detection</p><p>예를들어,<br>‘[the patient] was put on [Imatinib regimen]’ 이라는 문장에서<br>the first step detects the event trigger ‘put’,<br>the second step detects the theme ‘Imatinib regimen’ and target argument ‘patient’</p><p>Bjo¨rne et al<br>stenteces를 the McClosky-Charniak-Johnson parser을 사용하여 a dependency graph (stanford Dependency)로 변환하였다.<br>그리고, both steps을 위한 features를 만들기 위해 the graphs를 탐색했다.</p><p>the McClosky-Charniak-Johnson parser는 the constituency parser of Charniak and Johnson을 기반으로 만들어졌으며,<br>the biomedical domain model of McClosky와 함께 retrain 되었다.</p><p>이 방법의 경우에는 arguments 사이의 the shortest path of syntactic dependency를 기반으로 하는 event arguments와 연결하는 n-gram features를 발생시킨다.</p><p>Their system TEES performed best in<br>the 2009 GE (0.52 f-measure),<br>2011 EPI (0.5333 f-measure),<br>2013 CG (0.5541 f-measure),<br>2013 GRO (0.215 f-measure, being the only participating system)<br>2013 BB full-event extraction (0.14 f-measure).</p><p>Hakala et al.<br>TEES system의 top 을 만들고 , 그것의 output을 enriched graph-based features에 의해 re-rank 시켰다.</p><p>여기서 enriched graph-based features란<br>외부 PubMed abstracts and the PubMed Central full-text corpus로부터 mined된 general subgraphs에서의<br>paths connecting nested events and occurrence of gene-protein pairs</p><blockquote>
<p>nested events를 연결하는 Paths와 gene-protein pairs의 발생</p>
</blockquote><p>The system by Hakala et al. placed first in 2013 GE (0.5097 f-measure),<br>whereas the TEES system placed second (0.5074 f-measure).</p><p>graph-based features을 많이 사용하는 모든 systems의 strong performance </p><p>특히, Hakala et al. 이 enriched graph-based features 와 obtained better performance (first vs second)를 이용해 Bjorne et al을 확장시켰다는 사실은</p><p>the potential benefits of exploring graph-based features을 보여줌.</p><blockquote>
<p>기존의 방법을 이용하여 새로운 방법을 만들어냈는데 그것이 좋은 성능을 보이면서 relation extraction 분야에서의 exploring graph-based features가 좋은 방법임을 보여주었넹</p>
</blockquote><hr class="underscore"><p>Miwa et al.<br>the EventMine system을 만들었다.<br>이 the EventMine system은 biomedical events뿐만아니라 their negations and uncertainyt statements까지 추출해낼 수 있었다.</p><p>event extraction을 위해,<br>the Enju parser과 the GENIA Dependency parser(GDep)를 사용했다.</p><p>GDep는 dictionary based features와 함께 path features를 발생시키기 위해서!<br>(ex, UMLS Specialist lexicon and Wordnet)</p><p>Their entry in BioNLP-ST-2013 placed first in the PC task.</p><blockquote>
<p>지금 이 내용들이 community challenge를 위해 제출된 연구들<br>the PC task는 community challenge의 한 분야</p>
</blockquote><p>특히,<br>their path features는<br>paths between event arguments 뿐만아니라<br>paths between event argument and non-argument named entities 를 포함한다.</p><p>나중에 pahts들은<br>더 많은 local context features를 제공함으로써 strongperformance를 낼 수도 있다.</p><hr class="underscore"><p>또 다른 event extraction으로 제안된 연구로는</p><p>동시에 예측된 같은 문장에서의 모든 events에 대한 trigers and arguments에서의 </p><blockquote>
<p>????</p>
</blockquote><p>McClosky et al.<br>event extraction을 the overall dependency parsing objective 로 통합시켰다.<br>They 은 the McClosky-Charniak-Johnson parser과 변형된 the parsers들을 Stanford Dependency에 적용시켰다.<br>그들은 training data에서의 the annotated event structures을 event dependency graphs로 변환시켰다.</p><blockquote>
<p>event dependency graph 는<br>event arguments (named entities)를 node로<br>argument slot names를 edge로 둔 그래프이다.</p>
</blockquote><p>They 는 the vent dependecy graphs를 Stanford Dependency graphs 로 매핑했고,<br>확장된 MSTParser을 test data로부터 event dependency graphs를 추출하도록<br>train 시키기 위해 graph-based features를 만들었다.</p><p>Their graph-based features 은<br>the Stanford Dependency graph에서의 nodes간의 paths를 포함하고있고,<br>그들의 parents, childeren, siblings of the path nodes로 구성되는 subgraphs들도 포함하고있다.</p><p>그다음,<br>그들은 the top-n extracted event dependency graphs를 다시 event structures로 바꾸고,<br>the best one을 위해 event structures를 re-ranked 시켰다.<br>event dependency graphs로부터 같은 graph-based features를 사용하면서,</p><blockquote>
<p>event structure -&gt; event dependency graphs -&gt; event structures 구조구나</p>
</blockquote><p>Riedel et al<br>먼저, Markov Logic Networks를 event structures 를 익히는데 적용시켰고,<br>후에 graph-based methods로 변경했다.</p><blockquote>
<p>?</p>
</blockquote><p>They 는 events들을 labeled graphs로 보여주었고,<br>event triggers and arguments들에대한 제약들을 잡아내는 function을 사용하여 candidate graphs에 대해 점수를 매겼다.</p><p>The scoring function은<br>token features,<br>dictionary features<br>dependency path features<br>을 고려한다.</p><p>더 나아가,<br>그들의 모델과 McClosky et al 에 의한 the system과 combine 하기 위해<br>a stacking model을 사용했다.</p><p>The combined system은<br>first place in<br>2011 GE task (0.56 f-measure)<br>2011 ID task (0.556 f-measure)<br>에서 얻어졌다.</p><hr class="underscore"><p>경쟁적으로 수행된 most of the remaining BioNLP systems은 또한<br>규모를 다양화 하기위해서 graph-based features를 사용했다.</p><blockquote>
<p>규모를 다양화해?</p>
</blockquote><p>Liu et al.<br>an Exact Subgraph Matching (ESM) method를 개발했고,<br>후에 more flexible Approximate Subgraph Matching (ASM) method를 개발했다.</p><p>그들은 the McClosky-Charniak-Johnson parser과 함께 sentences을 처리했으며,<br>the parses을 directed dependency graphs로 변형시켰다.</p><p>그들은 the graph of an event 를 만들었다.<br>by computing unions of dependency paths between event arguments</p><blockquote>
<p>event arguments 사이의 dependency paths의 unions을 계산함으로써 </p>
</blockquote><p>그다음, 그들은<br>ESM/ASM를<br>sentence graphs 에서부터 event graphs까지 적용시켰다.<br>using a customized distance metric 을 사용하며,</p><blockquote>
<p>근데 distance metric는<br>graph structure,<br>node-covered stemmed words<br>edge directionality<br>에서의 subgraph differences를 설명하는 것</p>
</blockquote><p>그들은 그들의 메소드를 확장시켰다<br>Protein Data Bank(PDB)과 Uniprot 과 Biothesaurus를 통합함으로써<br>protein/residue names을 인식하기 위해,</p><p>그리고 그들의 메소드를 BioInfer 과 Uniprot corpus를 포함하는 다른 corpora에 적용시켰다.</p><blockquote>
<p>처음에는 PDB Uniprot Biothesaurus를 대상으로 하고 그다음에 다른 literature에 적용시켰넹</p>
</blockquote><p>This work 는 this lines of graph kernel-based methos를 형성했다.</p><p>일반적으로,<br>kernel methods는 간접적으로 similarity function 에 가중치를 매기며,<br>features는 오직 instance pairs의 similarity function을 평가하는데만 사용된다.</p><p>따라서,<br>Kernel methods는 종종 직접적으로 weight/rank 할 수 없다. features.</p><blockquote>
<p>왜냐하면 평가하는데만 사용되거든.</p>
</blockquote><p>Kilicoglu et al.<br>또한 the McClosky-Charniak-Johnson Parser/Stanford Dependency pipeline을 응용했다.</p><blockquote>
<p>the McClosky-Charniak-Johnson Parser 되게 많이쓰네</p>
</blockquote><p>그들은 the dependency graphs를</p><p>embedding graphs를 횡단하고, ( 탐색하고? )<br>nested events를 추출하기 위한<br>post-processing rules를 적용시키기 위해</p><p>embedding graphs 로 변환시켰다.</p><p>embedding graphs 란<br>nodes 자체 스스로 small dependency graphs가 되는것</p><p>그러나, their embedding graphs 는<br>argument erro propagation 과 부정확성이 발생했다.</p><blockquote>
<p>실패 ㅠㅠ</p>
</blockquote><hr class="underscore"><p>가장 인기있는 McClosky-Charniak-Johnson Parser/Stanford Dependency pipeline 에 비해서</p><p>몇몇 systems 는 different parsers and/or dependency representations 와 함께 실험을 진행했다.</p><p>Hakenberg et al<br>BioLG (a Link Grammar Parser extension) 을 parser trees를 발생시키는데 사용했다.</p><p>그들은 parser trees를 database 에 저장시켰으며,<br>subgraph pattern에 사용하기 위해 query language를 설계 했다.</p><p>subgraph patterns은 수동적으로 parse trees에 대항하여 training data 로부터 만들어진것.</p><blockquote>
<p>parse tree가 뭐지</p>
</blockquote><p>그들은 event types의 발생이 their result를 더 좋게 만들 수 있다는 점을 주목하였다.</p><blockquote>
<p>하고싶은 말이 뭐지 </p>
</blockquote><p>Van Landeghem et al.<br>the Stanford Parser로부터<br>training data와 these patterns 기반으로 만들어진 extraction rules 로부터<br>minimal event-containing subgraph patterns를 식별되어지면서,<br>dependenc graphs를 분석하였다.</p><blockquote>
<p>여기 해석 다시 해야 할듯?</p>
</blockquote><p>Their post-procssing rules는 overlapping triggers of different event types 과 같은 trigger, trading recall for precision 기반한 events들을 다룬다.</p><hr class="underscore"><p>The other systems는 일반적으로 event extraction을 위해 the dependency paths connecting the concept pair as features를<br>사용한다.</p><p>예를들어,<br>the dependencies 는 다른 parsers의 적용을 통해 얻어졌다.</p><p>parsers라고 함은, the Pro3Gres parser (Kaljurand et al.)<br>the RASP parser (Vlachos et al),<br>or both McClosky-Charniak-Johnson parser and Enju parser (Quirk et al) 를 말한다</p><p>그러나,<br>같은 Task에 있어서 이 메소드들 중 대부분은 비교적 좋지않은 성능을 보인다.<br>우리는 2가지 이유가 있다고 생각한다.</p><ol>
<li>the McClosky-Charniak-Johnson parser with the self-trained biomedical parsing model 은 이 분야에서 가장 정확한 parser이다.</li><li>the best systems에 의해 사용된것 처럼 the enriched graph-based features and event type generalization event extraction에서 매우 유용한 features를 만들어 낼 수 있다.</li></ol><h6 id="ppi-extraction-and-biocreative-shared-tasks"><a name="ppi-extraction-and-biocreative-shared-tasks" href="#ppi-extraction-and-biocreative-shared-tasks"></a>PPI extraction and BioCreative shared tasks</h6><p>BioCreative shared tasks 는<br>biomedical text에서의 genes and proteins에 대한 자동 named entityr recognition 과<br>이 entities들 사이의 the interaction을 추출하는 것에<br>집중한다.</p><p>the PPI task of BioCreative-2의 PPI task의 참가자 사이에서,<br>most of systems은<br>co-occurrence statistics,<br>pattern templates,<br>shallow linguistic features (eg. context words and part-of-speech tags)<br>들을<br>statistical machine learning 이나 rule-based systems 과 함께<br>을 사용했다.</p><blockquote>
<p>머신러닝 기법이나, 규칙을 기반한 분류기법을 사용했었어</p>
</blockquote><p>Some of systems는<br>the need for capuring cross sentence mentions of interacting proteins.<br>를 관찰했다</p><blockquote>
<p>상호작용하는 단백질들을 언급하는 문장에 대해 capture할 필요성</p>
</blockquote><p>예를들어, </p><p>Huang et al.<br>a profile-based method 를 개발했다.</p><p>method :<br>the document의 mutiple sentences로부터의 features를 통합함으로써,<br>candidate protein pairs를 위한<br>a vector representation를 만드는 메소드</p><p>The Profile features은<br>n-grams<br>직접 구성한 templates<br>relative positions of protein mentions<br>를 포함하고 있다.</p><p>In BioCreative-2.5 에서<br>the top teams in the PPI task를 기반으로<br>the organizers는 deep parsing and dependency tree/graph mining 을 사용한<br>the BioNLP techniques들이 중요한 결과를 성취하는데 필요하다는 것에 주목했다.</p><p>특히,</p><p>Hakenberg et al.<br>their BioNLP-ST-2009 entry system 과 비슷한 system을 사용했었다.<br>그들은 직접 training date로부터 subgraph patterns를 만들었고,<br>subgraph patterns를 against parse trees에 match 시켰다.</p><p>Their f-measure was 0.30.</p><p>Saetre et al</p><p>the Enju parser and teh GDep parser 을 사용했고,<br>relation extraction를 위해 concept pairs사이의 the dependency paths들을 features로 고려하였다.</p><p>이 방법의 f-measure은 0.374 이다.</p><p>The PPI tasks of BioCreative-3 는<br>PPI-related articles를 찾아내는 것 으로 구성되어있다.</p><p>여기서 PPI-related articles란<br>특정 PPIs 에 대한 증거를 제공하지만, the actual extraction of PPIs는 포함하지 않는 article을 말한다</p><blockquote>
<p>오 직접적인 PPIs 추출은 하지않지만, 특정 PPIs에 대한 증거를 제공해<br>네트워크를 구성하지않나?</p>
</blockquote><p>Several follow-up studies to BioCreative-2.5 은<br>kernels in PPI extraction, based on corpora including AIMed, BioInfer ,HPRD50 , IEPA and LLL<br>의 사용을 평가한다.</p><p>Studies는<br>kernels를 아래와 같이 카테고리화 한다.</p><p>(1) shallow linguistic (SL) kernels[140];</p><p>(2) constituent parse tree-based kernels,<br>including subtree (ST) [141], subset tree (SST) [142] and partial tree (PT) [143] kernels that use increasingly generalized forms of subtrees,<br>as well as a spectrum tree (SpT) [144] kernel that uses path structures from constituent parse trees; </p><p>(3) dependency parse tree-based kernels, including edit distance and cosine similarity kernels that are based on shortest paths [145]<br>k-band shortest path spectrum (kBSPS) [99] that additionally allows k-band extension of shortest paths,<br>all-path graph (APG) kernel [20] that differently weights shortest paths and extension paths in similarity calculation,<br>as well as Kim’s kernels [146] that combine lexical, part-of-speech and syntactic information along with the shortest path structures.</p><blockquote>
<p>한번 확인할것</p>
</blockquote><p>The comparative studis and error analyses 는 이것을 보여준다.</p><blockquote>
<p>위에것을 통해 연구ㅡㄹ 비교하고 에러를 분석해보면 이런 결과를 유추할 수 있따.</p>
</blockquote><p>(1) dependency tree-based kernels generally outperform constituent tree-based kernels;<br>(2) kernel method performances heavily depend on corpus-specific parameter optimization;<br>(3) APG, kBSPS and SL are top-performing kernels;<br>(4) ensembles based on dissimilar kernels can significantly improve performance;<br>(5) non-kernel-based methods (e.g. rule-based method, BayesNet) can perform on par with or better than all non-top kernel methods.</p><p>이러한 관찰로부터,<br>이것은 richer dependency graph/tree structures (e.g. in APG, kBSPS) than shortest paths은<br>graph/tree-based kernels,which is consistent with the analysis of BioNLP participating systems,<br>의 더나은 퍼포먼스를 위해 중요하다는 것의 증거이라는 것을 보여준다.</p><blockquote>
<p>dependency graph/tree structures가 뭔가 더 정보가 많으면, 성능이 좋아지는구나.<br>2번 같은 뭐 그런거<br>의존한다는것 자체를 보여주네</p>
</blockquote><p>The limited advantage of the kernel methods는<br>non-kernel methods와 kernel methods와 연관된 해석의 어려움을 넘어<br>새로운 kernel functions보다는 새로운 features sets을 조사하는데 더 존재하는것 같다.</p><h6 id="ddi-extraction-and-ddiextraction-shared-tasks"><a name="ddi-extraction-and-ddiextraction-shared-tasks" href="#ddi-extraction-and-ddiextraction-shared-tasks"></a>DDI extraction and DDIExtraction shared tasks</h6><p>The two DDIExtraction Challenges (2001 and 2013)은<br>biomedical text로부터 DDI의 자동추출을 목표로 하였다<br>The organizers of the two challenges들은<br>직접 curated DDI databases를 업데이트 하는데 있어서<br>the extended delays를 발견했다.</p><blockquote>
<p>DB update에 어려움이 존재했대</p>
</blockquote><p>그들은 the medical literature 와 technical reports가 the detection of DDIs에 가장 효과적인 sources이지만,<br>엄청난 양의 data를 포함하고 있는 단점을 가지고 있는것을 발견했다.</p><p>따라서,<br>DDIExtraction 은<br>Accurate automated textmining approaches를 위해 the pressing need에 의해 동기부여 되었다.</p><blockquote>
<p>pressing need 꼭 필요한 nees 라고 무난하게 해석하자</p>
</blockquote><p>DDIExtraction-2011은<br>candidate drug pairs 사이에 어떤 interaction이 존재하는지 안하는지 구분하는 것에 집중했다.</p><p>DDIEtraction-2013은 추가적으로<br>detailed classification of DDI into one of the four possible subtypes 를 추구했다.</p><p>advice (advice regarding the concomitant use of two drugs),<br>effect (effect of DDI),<br>mechanism (pharmacodynamics or pharmacokinetic mechanism of DDI)<br>int (general mention of interaction without further detail).</p><p>In DDIExtraction-2011,<br>Thomas et al<br>the McClosky-Charniak-Johnson parser/Stanford dependency pipline을 적용했다.<br>그들은 직접적으로 relation extraction을 위해 features를 잡아내기 위한 the follwing kernels 를 투표를 통해 통합했다.<br>APG [20], kBSPS [99] and SL [140] kernels.<br>Their best f-measure was 0.657.</p><p>Chowdhury et al<br>the Stanford parser를 dependency trees 를 얻어내는데 사용하고<br>relation extraction을 위해<br>feature-based methods와 kernel-based ensemble methods 둘다와 함께 실험을 진행했다.<br>그들은<br>mildly extended dependency tree (expanding shortest paths to also cover important verbs, modifiers or subjects)<br>and path-encoded tree  kernels. (based on constituency tree)<br>를가지고 SL 실험을 진행했다.</p><blockquote>
<p>SL ( Swallow Linguistics )</p>
</blockquote><p>feature-based and kernel-based methods를 통합함으로써,<br>They achieved the second best f-measure of 0.6398</p><p>In DDIExtraction-2013,<br>그들은 r그들의 previous kernel method를 사용했지만,<br>그러나 the McClosky-Charniak-Johnson parser로 변경했고,<br>the parses를 Stanford Dependency로 변환하였다.<br>이 방법의 일반적 classification에서는 f-measure은 0.80이였고<br>이 방법의 구체적 classification에서는 0.65가 나왔다.</p><p>Thomas et al 경우 a two-setp approach를 따랐는데,</p><ol>
<li>general DDIs를 감지하고</li><li>그다음, 감지된 DDIs를 subtypes를 통해 분류한다.</li></ol><p>the general DDI task를 위해,<br>그들은 kernels를 통합하는데 투표를 진행했다.</p><p>kernel : APG [20], subtree (ST) [141], SST [142], SpT [144] and SL [140] kernels.</p><p>For the subtype classification step,<br>그들은 직접저긍로 TEES를 사용했다.<br>Their system은 second best with an f-measure of 0.76 for general classification and<br>0.609 in detailed classification.</p><p>이것은 PPI extraction 이나 Event extraction을 위해 개발된 systems의 적용이 DDIExtraction에서도 최고의 성능을 나타낼 수 있는 흥미로운 결과도 보여준다.</p><p>이는 더 나아가 these tasks이 더 가깝게 연관이 있다는 것과,<br>한가지를 위한 technical solutions는 다른것에도 일반화 될 수 있다 라는 것을 보여준다.</p><blockquote>
<p>tasks 들이 서로 연관이 있으니까 한가지 메소드로도 서로 적용이 가능하다는것을 보여준 사례라고 볼 수 있겠다</p>
</blockquote><h6 id="pharmacogenomics"><a name="pharmacogenomics" href="#pharmacogenomics"></a>Pharmacogenomics</h6><p>약리유전학에서는,<br>genetic mutations 와 drug response phenotypes사이의 흥미로운 관계들을 밝혀내기 위한<br>literature and clinical text의 사용을 중심으로 많은 노력들이 이루어 지고 있다.</p><p>비록 이것들의 성능은 서로 공유된 corpora를 사용하는것이 아니끼 때문에 비교하기 힘들지만,<br>이 approaches들은<br>the translational application and<br>adaptation of some state-of-the-art biomedical relation extraction techiniques,<br>clinicians and pharmacologits에 의해 직접 요구되어진 문제들에 대한 </p><hr class="underscore"><p>Some systems는 path-based approaches를 사용한다.</p><p>Coulet et al<br>pharmacogenomics를 위한 semantic networks를 만들기 위해<br>genes, drugs and phenotypes 사이의 binary relations를 추출하는 것에 집중한다.</p><blockquote>
<p>네트워크 만들라고</p>
</blockquote><p>They는 먼저, the Stanford Parser output on sentences (from collected PubMed abstracts)를<br>dependency graphs로 변환했다.</p><p>그들은 name entities로부터 시작하고 verbe에서 끝나는 path를 추적했다.</p><p>그들은 빈번한 relations 을 얻어냈고,<br>the collected entities와 relation types (verbs) 둘다 표준화했다.</p><p>relation types의 열거 순서를 요구하는 것 없이,<br>그들은<br>의미론적으로 풍부한 rich summaries of pharmacogenomics relations 를 제공하는<br>a semantic network knwledge based 를 만들어냈다.<br>from 17 million MEDLINE abstracts, </p><p>Percha et al.<br>the dependency graph에서 two named entities간 the shortest path를 산출해서<br>relation extraction을 위한 features를 발생시키기 위해<br>BFS를 사용하도록 this approach를<br>연장시켰다.</p><blockquote>
<p>this approach?</p>
</blockquote><p>그들은 the extracted gene-drug relations를 DDIs를 추론하기 위해 통합시켰다<br>the same gene product와 함께 상호작용하는 those drugs들을 기준으로,</p><p>wang et al<br>잠재 Dirichl et al location을 a semantic representation of biomedical named entities 를 만드는데 사용했고,<br>Kullback-Leibler(KL)divergence 를 in the Chem2Bio2RDF semantic network에서의<br>pairs of entities 간의 the association distance를 계산하기 위해 사용했다.</p><p>그들은 candidate associations between named entitiy pairs를 summing distance along the path connecting the pairs 으로<br>서열을 나누었다.</p><p>그들은 새로운 knowlege discovery의 사용을 보여주었다.<br>searching and predicting novel gene-drug associations<br>traversing the mined semantic network to compare the molecular therapheutic and toxicological profiles of candidate drugs.</p><hr class="underscore"><p>Other systems 는 tree-based approaches를 사용한다.</p><p>Katrenko et al<br>gene-protein relation과 protein-protein relation extraction을 연구하고,<br>the dependency parse trees에서<br>두 named entities들의 가장 가까운 공통조상을 뿌리로 하고있는<br>the subtrees를 features로 두고 있다.</p><p>Their experiment는 the Link Gramar Parser, Minipar and the Charniak Parser을 포함한 몇몇 parsers를 사용하고있다.</p><p>각각의 parser의 결과를 비교했을때,<br>그들은<br>adopting ensembel methods (stacking and AdaBoost) 와<br>Combining multiple parsers’ results의 통함으로부터<br>향상된 성능이 나오는것 을 확인했다.</p><p>Hakenberg et al<br>gens, SNP variants, drugs, ADRs사이의 relations를 추출하는 것을 목표로 하고있었다.<br>그들은 특정 relations의 추출을 위해 co-occurrence에 의존했다.<br>(e.g. gene-drug, gene-disease and drug-disease)<br>그러나 the Stanford Parser output for other types of relations로부터<br>subtrees와 함께 co-occurrence 증가시켰다.<br>but augmented co-occurrence with subtrees<br>from the Stanford Parser output for other types of relations.</p><p>그들은 binary relations 를 고려했고, 공통조상을 가지고있는 named entity pairs의 subtrees를 사용했다.</p><p>The mined relations are cross-referenced with knowledge bases including EntrezGene, PharmGKB and PubChem.</p><p>Bui et al<br>HIV drug resistance을 예측하기 위해 drugs and virus mutations 간의 관계를 추출하는 것을 목표로 했다,</p><p>그들은 Stanford Parser 를 constituent parse trees for sentences를 만드는데 사용했다.<br>그리고 그들은 drug-gene relations를 추출하기 위해 트리구조를 탐색할 수 있는 grammatical rules를 개발했다.<br>그들의 System은 연구에서 새로운 HIV drug resistance candidates을 먼저 선택하기위해 5개의 병원들에서 사용되고있다.</p><hr class="underscore"><p>Pharmacogenomics에서 path-based systems 와 tree-based systems 은<br>다수의 shared tasks에서 사용되는 the balanced f-measure와는 다르게<br>그들의 평가에서 recall 보다는 precision에 더 집중하는 경향이 있다.</p><p>이는<br>pharmacogenomic semantic networks를 만들고 발전시킬수 있는<br>믿을만한 관계를 찾아내려고 하는 특정한 목표로부터 나온 것같다.</p><p>Too much noise는 초기 semantic network를 cloud 할 수 있다.<br>반면에, missing relations는 더 많은 literature를 사용함으로써 나주에 발견될 여지가 여전히 존재한다.</p><p>사실, 보고된 precisions for pharmacogenomics relation extraction system은<br>전형적으로 70%~80%이다.<br>게다가,<br>이 systems은 종종<br>PharmGKB와 같은 curated database로부터 반대되는 relations을 추출한다.</p><p>우리는 이 systems들이<br>biomedical models로 parser들을 훈련시켜 적응시키고,<br>enriched grap-based features를 사용함으로써,<br>더 나은 이익을 줄 것으로 보인다.</p><p>위 두개는  two of the most recent lessons learned in shared takss. 이다.</p><h5 id="relation-extraction-from-clinical-narrative-text"><a name="relation-extraction-from-clinical-narrative-text" href="#relation-extraction-from-clinical-narrative-text"></a>Relation extraction from clinical narrative text</h5><p>The medical informatics community는 또한<br>확장적으로<br>shared tasks 와 seperately motivated research의 형태에서의<br>relation extraction을 연구한다.</p><p>예를들어,<br>EMRs의 narrative text으로부터의 semantic relations 추출에서 중요한 발전은<br>the i2b2/VA-2010 challenge<br>(i2b2—Informatics for Integrating Biology to the Bedside,VA—Veterans Association)로<br>작성되어 왔다.</p><h6 id="i2b2/va-challenge"><a name="i2b2/va-challenge" href="#i2b2/va-challenge"></a>i2b2/VA challenge</h6><p>The challenge는 3가지 tasks를 가지고있다.<br>1.concepts extraction<br>2.assertion classification<br>3.relation classification, participated by numerous international teams.</p><p>Concepts extraction 는<br>Assertion and Relations 모두 the extracted concepts로 표현되기 때문에<br>기초적 단계로 고려되어질수있다.</p><p>the challenge가 relation classification이 the ground truth of concepts extraction을 사용할수 있도록 허용하기 때문에,<br>relation classification의 the performance metrics는  an upper bound for the end-to-end relation extraction task<br>(same as the challenges from BioNLP, BioCreative and DDIExtraction)<br>로써 해석되어질 필요가있다.</p><p>In this section,</p><p>우리는 오직 medical problems, tests, and treatements 사이에서 the target relations 이 미리 정의되는 the relation classification system을 리뷰할 것이다.</p><p>이들의 relations들은<br>‘treatment improves / worsens / causes / is administered for / is not administered because of medical problem’,<br>‘test reveals /conducted to investigate medical problem’and<br>‘medical problem indicates medical problem’<br>을 포함하고있다.</p><p>위의 challenges를 리뷰함에 있어서 처럼,<br>우리는 단지 sentences를 그래프처럼 보여주고,<br>the feature-generation step 동안 such graphs를 탐험하는<br>those system 들을 리뷰할 것이다.</p><hr class="underscore"><p>Robert et al.<br>꽤 포괄적인 set of features을 사용하여 the semantic relations를 분류했다.</p><p>context features (e.g. n-grams, GENIA part-of-speech tags surrounding medical concepts),<br>nested relation features (relations in the text span between candidate pairs of concepts),<br>single concept features (e.g. covered words and concept types),<br>Wikipedia features (e.g.concepts matching Wikipedia titles),<br>concept bi-grams features<br>and similarity features.</p><blockquote>
<p>이것들을 사용해서 분류했대</p>
</blockquote><p>그후 GENIA pharse chunks and Stanford Dependency shortest paths를 포함하는 언어적 산물의 edit distance를 사용하여<br>computed 되었다.</p><p>Their system은 the hight f-measure on realtion classification 0.737에 도달했다.</p><p>deBruijin et al.<br>the relation distribution을 균형잡기 위해 적용된 down sampling 과 함께<br>a maximum entropy classifier을 적용했다.</p><p>그들은 the McClosky-Charniak-Johnson parser/Stanford Dependency pipeline을 사용했으며,<br>the concept pairs를 cover 하는 the minimal trees간의 the dependency paths를 feature로써 포함시켰다.</p><p>그들은 the problem of unseen words를 보여주기 위해 word clusters를 features로 사용했다<br>그들의 시스템은 the second best f-measure of 0.731에 도달했다.</p><p>Solt et al.<br>그다음 몇몇 parser<br>includin the Stanford Parser, the McClosky-Charniak-Johnson Parser and the Enju Parser.<br>로 진행을 했다</p><p>그들은<br>including the all paths graph(APG) kernel [20] and kBSPS [99], which produced only moderate performance<br>두개의 그래프 kernels와 함께<br>the resulting dependency graphs를 사용했다.</p><p>이것은 the graph/tree kernel-based systems 을 튜닝하는데 있어서 어려움을 보여준다.</p><p>the scientific literature로부터의 relation/event extraction에서의 the experience로부터의<br>일관된 관찰과 함께</p><h6 id="semeval-2015-task-14"><a name="semeval-2015-task-14" href="#semeval-2015-task-14"></a>SemEval 2015 Task 14</h6><p>The SemEval 2015 Task 14 는<br>disorder identification<br>disorder slot filling tasks<br>포함한다</p><p>Disorder identification is 필수적인 named entity detection 이며<br>Disorder slot filling task is BioNLP event extraction tasks 와 비슷하지만,<br>clinical subdomain에서 사용되는 차이가 있다.</p><p>더 나아가 The challenge the slot filling task를 두개의 subtasks로 나눈다.<br>one with gold-standard disorder spans (task 2a)<br>one without (task 2b)</p><p>따라서,<br>task 2b 는 task 2a에 비해 더 엄격한 평가 결과를 가진다.</p><p>The challenge에 의해 정의된 the attribute slots 은 </p><p>concept unique identifier (CUI)<br>negation (NEG)<br>subject (SUB),<br>uncertainty (UNC),<br>course (COU),<br>severity (SEV),<br>conditional(CND),<br>generic (GEN) and<br>body location (BL).<br>를 포함한다</p><p>the CUI을 식별하는 것은 the named entity-detection problem 이다.<br>그리고, negation and uncertainty을 식별하는 것은 the assertion classification problem 이다.</p><p>SUB, COU, SEV, CND, GEN and B 을 식별하는 것들은 binary relation extraction과 더 유사하다.</p><p>그것들은<br>asthe challenge limited the possible values for those slots,<br>a layer of abstraction을 추가하면서,<br>완전하게 binary relation extraction과 동등하진 않다.</p><hr class="underscore"><p>The challenge 는<br>the participants의 서열을 나누기 위해<br>가중치가 적용된 accuracy를 사용한다.</p><p>Xu et al. and Pathak et al.은<br>일관성있게<br>the top two teams in both task 2a (0.886 and 0.880, respectively)<br>and task 2b (0.808 and 0.795, respectively).<br>서열을 나눈다.</p><p>Xu et al.<br>BL slot filling 을 위해<br>Conditional Random Field (CRF) 를 the classifier로 사용한다.</p><p>그리고 other slots을 위해<br>SVM을 the classifier 로써 사용한다.</p><p>추가적으로 The SVM classifier는 the disorder mentions의 into and out 에서의 dependencies를 사용한다.</p><p>these dependencies는 multi-hop syntax dependence를 잡아낼순없지만,<br>저자들은 that NEG/UNC/COU/SEV/GEN always have one-hop dependence 를 관찰한 것을 주목해라</p><p>반면에,<br>CRF (for BL) 는 그것 자체가 tokens 과 hidden staes 를 노드로써 사용하고<br>(integrating semantic and syntactic features including n-grams, context words, dictionaries and section names)<br>interconnects nodes with transition and emission edges 를 사용함으로써<br>로 graph-based model 이 된다.</p><p>Pathak et al.<br>slot detection을 두 부분으로 나누었다.</p><p>1.detecting keywords<br>2.relating keywords with disorder mentions.</p><p>그들은<br>bag-of-words 와 orthographic features to detect keywords와 같은 features로 훈련된 CRF과 함께 통합된<br>dictionary look-up ( 검색 ) 을 사용했다.</p><p>keyword를 disorder mentions와 연관짓기 위해,<br>그들은 Xu et al과 비슷한 features에다 Part-of-Speech tags를 추가적으로 사용하면서, SVM를 훈련시켰다.</p><p>Other teams는 간접적인 graph-mining algorithms을 사용했다.<br>그리고, 그러나 경쟁적으로는 사용되지않았다 ?</p><blockquote>
<p>?</p>
</blockquote><p>예를들어,</p><p>Hakala et al.</p><p>TEES system을 SemEval data foramt과 함께 작동될 수 있도록 적용시킴으로써 task 2a를 다뤘고,<br>3위에 해당하는 a weighted accuracy of 0.857를 성취했다.</p><p>이것은 주어진 many slot이 one-hop dependencies를 포함하고 있기 때문에, 놀랄일이아니다.<br>full-fledged graph-based approach는 오직 한정된 benefits를 제공한다.</p><p>게다가,<br>the controlled vocabulary and controlled format nature of challenge tasks는 그들 자체로<br>CRF에 맞게 만들어진다.<br>states and state-transitions의 한정된 숫자가 덜 빈약하고 더 튼튼한 probability estimation으로 이끌기 때문에,</p><h6 id="separately-motivated-clinical-relation-extraction"><a name="separately-motivated-clinical-relation-extraction" href="#separately-motivated-clinical-relation-extraction"></a>Separately motivated clinical relation extraction</h6><p>After the i2b2 challenges,<br>몇몇 authors 는 the concept and relation extraction steps를<br>통합된 pipeline and/or generalizing to the extraction of complx or even nested relations 로써 통합하는 것을 목적으로했다.</p><blockquote>
<p>통합충~~</p>
</blockquote><p>Xu et al.<br>a rule-based system MedEx을 만들었다.<br>이는, medications 와 그것들과 연관된 strenghs, routes and frequencies간의 특정 관계들을 추출하는 system이다.</p><p>The MedEx system은 narrative sentences in clinical notes를<br>conceptual graph representations of medication relations로 변환한다.</p><p>이것을 그렇게 하기위해,</p><p>Xu et al은 직접 conceptual graphs로 mapping 할 수 있는 a semantic grammar를 설계했고,<br>이 grammar에 따라 sentences를 parse 할 수 있게 the Ky Chart Parser를 사용했다.</p><p>그들은 또한<br>regular-expression-based cunker을<br>the Kay Chart Parser가 놓친 medications를 잡아내는데 사용했다.</p><p>Weng et al.<br>a customized syntactic parser을 text spcifying clinical eligibility criteria에 적용했다.</p><p>그들은 maximal frequent subtree patterns를 추출했고,<br>직접 통합했으며,<br>그것들을 the UMLS와 함께 enrich 하게 했다.<br>a semantic representation for eligibiltiy criteria which aims to enable semantically meaning ful search queris over ClinicalTrials.gov 하기 위해.</p><p>Luo et al.<br>the Stanford Parser을 UMLS-based concept recognition과 함께<br>정확하게 graph representations for sentences in pathology report 하도록 발전시켰다.</p><p>여기서 pathology report란 the graph nodes가 medical concepts와 같은 것.</p><p>그 다음 빈번하게 나타나는 subgraph mining 은<br>medical concepts간의 중요한 semantic relations을 모으는데 사용되었다.<br>(e.g. which antigens are expressed on neoplastic lymphoid cells)<br>which serve<br>as the basis for classifying lymphoma subtypes.</p><p>Luo et al.<br>위의 the subgraph-based feature generation을 unsupervised learning으로 연장시켰다.</p><p>Luo는 더 나아가 tensor factorization을 subgraphs를 그룹짓기위해 사용했다.</p><p>The intuition (직관적 통찰)은<br>각 subgraph가 test result와 일치하고,<br>subgraph group이 test 이 전형적으로 진단 가이드라인에서 사용되는 것처럼 a panel of test results를 보여주는것이다.</p><p>The tensors 3개의 차원을 통합했다.<br>patients, common subgraphs and individual word in each report.</p><p>The words는 subgraphs들을 더 낫게 group화 하는것에 도움을 준다.<br>lymphoma subtype diagnostic criteria 을 회복하는 것을 위해서</p><h5 id="shared-resources-for-relation-extraction"><a name="shared-resources-for-relation-extraction" href="#shared-resources-for-relation-extraction"></a>Shared resources for relation extraction</h5><p>The shared tasks and separately notivated research on biomedical relation extracation은<br>오직 the state-of-the-art in methodology 발전한게 아니라<br>the utilzation of a repository of shared resources 를 만들고 보여주었다.</p><p>shared resources 는 knowledge bases 부터 shared corpora to graph ming toolkits까지의 범위.</p><p>우리는 카테고리화하고 요약해놓았다.<br>이 resource들을<br>Table 3에</p><p>미래의 연구 노력을 위한 resource navigation의 시작 포인트로써 제공되길 바란다.</p><p>Some of those resource는 일반적인 분야와 연관이 있다.<br>(e.g. general terminology/ ontology resources Wordnet [118], Verbnet [163]);</p><p>Some 은 포괄적으로 the biomedical domain과 연관이 있다.<br>(e.g. domain-specific terminology/ontology resources Gene Ontology [161], UMLS [58], Medical Subject Heading [162] and Biothesaurus [122]);</p><p>Some 은 target-specific biomedical subdomain<br>(e.g. knowledge bases such as PDB [101], Uniprot [121], SIDER [164], DrugBank [165], HIVDB [166], RegaDB [167], Entrez Gene [153], GENA [18]<br>and IntAct [169])</p><h5 id="lraod-ahead"><a name="lraod-ahead" href="#lraod-ahead"></a>Lraod ahead</h5><p>비록 graph-based algorithms을 the extraction of biomedical relations에 적용시킴에 있어서  주목할만한 과정들이 발견되었지만,<br>실용적인 relation extraction methods 를 개발하는데 있어서 장벽은 generalizable and sufficiently accurate 이다.</p><blockquote>
<p>일반화와 그리 높지않은 정확성</p>
</blockquote><p>밑에 우리는 몇몇 장벽과 이를 극복할 수 있는 잠재적인 방향에 대해서 설명해놓았다.</p><h5 id="not-all-parsers-and-dependency-encodings-are-synergistic"><a name="not-all-parsers-and-dependency-encodings-are-synergistic" href="#not-all-parsers-and-dependency-encodings-are-synergistic"></a>Not all parsers and dependency encodings are synergistic</h5><h5 id="모든-parsers와-dependency-encodings는-synergistic-한것은-아니다."><a name="모든-parsers와-dependency-encodings는-synergistic-한것은-아니다." href="#모든-parsers와-dependency-encodings는-synergistic-한것은-아니다."></a>모든 parsers와 dependency encodings는 synergistic 한것은 아니다.</h5><p>반복적으로 the choice of the parser and dependency encdoings 는 relation extraction system’s performance에서 중요한 역할을 할지도 모른다는 것은 주목 할만한다.</p><p>Buyko et al.<br>the impact of graph encoidng based on different parser<br>(Charniak-Johnson, McClosky-Charniak-Johnson, Bikel, Gdep, MST, MALT)<br>and dependency representations  에 대한 compative analysis를 수행했다.<br>(Stanford Dependency and CoNLL dependency).</p><p>그리고<br>the CoNLL dependency representation 이<br>the Stanford Dependency representations보다 4개의 parser를 통합해서 사용하는 것에있어서<br>더 나은 성능을 보여준다는것을 발견했다.</p><p>그리ㅗㄱ<br>McCLosky-Charniak-Johnson parser 은 빈번하게 가장 성능 좋은 parser이기도 했다.</p><p>Miwa et al. 같은경우<br>BioNLP-ST-2009 를 위해 five syntactic parser 를 비교했다.</p><p>그들은<br>비록 각각 parsers를 사용하는 것으로부터의 성능은 크게 차이나지않지만,<br>parsers 여러개를 쓰거나, 다른 dependency representations를 쓰는것은 the event extraction results를 크게 향상시킬수 있다고 결론지었다.</p><blockquote>
<p>혼합해서 쓰는게 좋다고하네여</p>
</blockquote><p>Stanford Dependency 는 the most wideely used dependency encoding 이기 떄문에,<br>그들은 또한 이에대해 다양한 다른 Stanford Dependecy variants들을 사용하였고,<br>만약 dependency edges의 types가 유지된다면  basic dependency 가 최고성능을 보인다는 것을 발견했다.</p><p>반면에,<br>만약 types of dependecy edges를 무시한다ㅕㄴ,<br>그들은 the collapsed dependency variant 가 최고의 성능을 보여준다는것을 발견했다.</p><p>Luo et al 에 의해 밝혀였다.</p><p>In [49] 에서,<br>the task 는 relations를 lymphma subtypes를 분류하기위한 features로써 추출하는 것이였다.<br>in the BioNLP_ST event extraction tasks에서 superviesed relation classification에서 처럼<br>그들 자체를 분류하는것 대신.</p><p>따라서, recall은 the feature learning step에서 관심이 있는 것이 되었다.<br>the feature learning step이란 types of dependencies를 무시하는 것이 the coverate of subgraph patterns 향상에 도움을 주는것,</p><p>이를 통해서 배운 The lessons은 각 challenges로부터의 top participants로부터 각각 reports들이 확립된 것처럼 보인다.</p><p>그리고 The lessons들은 parser-dependency choice의 인기와 함께 consistent 이다.<br>non-challenge applications in sections Pharmacogenomics and Sepearately motivated clinical relation extraction.</p><p>특히,<br>우리는 good combination은 the McClosky-Charniak-Johnson parser 나 Stanford parser augmented with medical lexicon 으로부터 선택하는 것이라고 기대한다</p><p>그리고 either CoNLL dependency or collapsed Stanford dependency 으로부터 선택하느 ㄴ것.</p><p>Intergrating coreference resolution<br>Coreference는 빈번하게 biomedical literature 나 clinical narrative text에서 발생한다.<br>the same concepts을 위해 prounouns, anaphora and varied entities의 사용으로부터 발생하면서,</p><p>Care must be exerciesd to transfer the correct relation along the coreference chain.</p><p>그러나, relation and event extraction을 위한  Many of the reviewed approaches는 a built-in coreference resolution component를 가지고 있지않다.</p><p>Miwa et al<br>구체적으로<br>the impact of using a coreference resoulution 에 대해 연구했고,<br>improved event extraction performance 를 보여주었다.</p><p>특히,<br>그들은 a rule-based coreference resolution system을 개발했는데.<br>이는 detecting rules for mextion antecedent and coreferential link로 구성되어있다.</p><p>그들은<br>the coreference information을 syntactic parse results를 조절하는데 사용했다<br>antecedent and mention share dependencies</p><p>Features는 또한 확장되었다 between mentions and antecedents.</p><p>the importance of coreference features를 recognizing 하면서,<br>그후에 몇몇 systems는 across sentences 하여 coreference resoulition 을 보충했다</p><p>그들은 relations의 특정 types을 추출하는 것을 촉진하기 위해,<br>heuristic/rule-based coreference resoulition이 domain-adapted statistical machine learning systems를 능가하는 경향이 있다는 것을 보여주었다.</p><p>Part of their lessons 는 in relation extraction corpora에서 the lack of gold-standard coreference anotation을 걱정했다</p><p>따라서,<br>우리는 기대한다.<br>paired relation and coreference annotations 는<br>coreference resolution and ultimately relation extraction 을 향상시킬수 있다는 것을.</p><p>게다가,<br>coreference resolution을 the learning objective of relation extraction에 통합하느 ㄴ것은<br>더 포괄적인 최적화와 더나은 end-to-end performance로 이끌지도 모른다.</p><h6 id="general-relation-and-event-extraction-and-domain-adaption"><a name="general-relation-and-event-extraction-and-domain-adaption" href="#general-relation-and-event-extraction-and-domain-adaption"></a>General relation and event extraction and domain adaption</h6><p>최신 relation and event exttraction systems from shared tasks 는<br>대부분 around domain-specific definitions of relations and events, many of which are in fact binary (PPI, DDI) and i2b2/VA challenge<br>이다.</p><blockquote>
<p>그니까 요즘 relation and event extraction system은 모두 일반적으로 사용할수 있는 툴이 아닌 특정 분야를 대상하로 한 툴.</p>
</blockquote><p>그러나,<br>the technical advances and the demands from many rea-world tasks 사이에는<br>pharmacogenomics semantic networks를 만들고,<br>clinical trial eligibility criteria 를 추출하고,<br>test results for automating diagnosis categorization을 보여주는데 있어서,<br>gap이 존재한다.</p><blockquote>
<p>무슨 차이가 존재하지</p>
</blockquote><p>In those tasks,<br>general relation and event discovery는 필수적이다.<br>where nodes의 숫자가 때때로 바뀔수있고,심지어는 the relation/event structure가 전체적으로 prespecified 되어있지 않을지도 모른다.</p><blockquote>
<p>relation event structure가 우리가 모르는 특정한 것에 대한 relation/event일 수 있다라는 거지</p>
</blockquote><p>the automation of annotaion scheme learning or unsupervised relation extraction을 탐색하는<br>Systems는 일반화 하려는 시도를 했었다.<br>그러나 여전히 accuracy를 증가시키는데있어서 큰 여지가 존재한다.</p><p>Another challenge는 domain-specific relation/event definition에 의해서 가져온 것인데,<br>Another challenge는 the training data를 염려한다.</p><blockquote>
<p>? 무슨 뜻이지</p>
</blockquote><p>THe problem of limited training data 는<br>종종 NLP systmes의 개발을 괴롭힌다.<br>the relation extraction systems는 예와가 없다.</p><p>더나은 존재하는 annotated corpora의 사용을 만들기위해,<br>domain adaptation from external training corpora(source) to the target corpora를 수행하는 것은 필수적이다.</p><blockquote>
<p>외부의 training corpora를 the target corpora로 적용시키는 것이  뭐하는걸까</p>
</blockquote><p>단지,<br>top systems 을 the new format에 adapting 하는것과<br>training on the new corpora 하는 것은<br>새로운 분야에서의 top performers로 이끄는 것은 아니다.</p><blockquote>
<p>?/</p>
</blockquote><p>예를들면, the adapted TEES system in SemEval 2015 Task 14</p><p>Miwa et al은<br>adding<br>source instances followed by instance reweighting when source<br>and target match on events to be extracted.</p><p>When source and<br>target corpora have a partial match on events,<br>그들은 각 event extraction module을 분리적으로 train 시키는 것을 제안했었다. on the source corpora<br>그리고<br>이것의 output을 additional featrues로써 사용했다. for the corresponding modules on the target copora.</p><p>더나아가 Miwa et al.<br>가짜 negative examples를 걸러내는 heuristics를 통합함으로써,<br>corpora를 combining 하는것의 methods를 향상시켰다.</p><p>The heuristics 은 에러를 맞추는데 목적이 있다.<br>이 에러는 where instances with a ‘None’ annotation<br>in one corpus owing to a different focus are all treated as negative<br>instances in the combined corpus.</p><p>7개의 event-annotated corpora로부터 learning에 method를 적용시키면서,<br>그들은 two tasks에서 향상된 성능을보여주었다.<br>BioNLP-ST-2011에서,</p><p>The successes from cascaded training and example filtering heuristics illuminate some promising directions in corpora adaptation. We expect parallel efforts in system generalization<br>and corpora adaptation can complement each other toward<br>effective domain adaptation.</p><p>Redundancy in subgraph patterns</p>

<footer style="position:fixed; font-size:.8em; text-align:right; bottom:0px; margin-left:-25px; height:20px; width:100%;">generated by <a href="http://pad.haroopress.com" target="_blank">haroopad</a></footer>
</body>
</html>
